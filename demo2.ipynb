{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenDartReader\n",
    "import pandas as pd \n",
    "import os\n",
    "import glob\n",
    "\n",
    "df = pd.read_csv('esg_finance_data.csv', dtype={'corp_code': 'str', 'stock_code': 'str'})\n",
    "df['year'] = ['2020'] * 847 + ['2021'] * 847 + ['2022'] * 847\n",
    "df['year'] = df['year'].astype('int')\n",
    "print(df.dtypes)\n",
    "print(df.shape, len(df.corp_code.unique())) #847\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결 재무제표 데이터\n",
    "\n",
    "api_key = '1ee244d6168bde153cb2d45463d71139f567d1f4'\n",
    "dart = OpenDartReader(api_key)\n",
    "\n",
    "def report_docu(code, year):\n",
    "    lst = dart.list(code, start='2019', end='2024') # 2019-2024 모든 보고서에서 데이터 찾아오기\n",
    "    \n",
    "    # 변경1: 원하는 년도의 사업 보고서 고르기 \n",
    "    report_num = lst[(lst['report_nm'].str.contains('사업보고서'))&(lst['report_nm'].str.contains(str(year)))].iloc[0, 5]\n",
    "    url = dart.sub_docs(report_num) #사업보고서 번호를 통해 url 요청\n",
    "    html = url[url['title'].str.contains('연결재무제표')].iloc[0, 1] # url 주소\n",
    "    \n",
    "    docu = pd.read_html(html) # 데이터 읽어오기 \n",
    "    if docu[1].empty | docu[3].empty: # [1] 재무상태표 [3] 손익계산서\n",
    "        print('Some document cannot be extracted')\n",
    "    else:\n",
    "        fin_state = docu[1].rename(columns={'Unnamed: 0': 'tag'})\n",
    "        fin_state = fin_state[(fin_state['tag'].str.contains('자산')) | (fin_state['tag'].str.contains('부채'))] # 재무상태표\n",
    "        # asset = fin_state[fin_state['tag'] == '자산총계'] # 자산 총계 DF\n",
    "        # debt= fin_state[fin_state['tag'] == '부채총계'] # 부채 총계 DF\n",
    "        # intangible = fin_state[fin_state['tag'].str.contains('무형자산')] # 무형자산 DF\n",
    "        income = docu[3].rename(columns={'Unnamed: 0': 'tag'}) # 손익계산서DF\n",
    "        income = income[income['tag'].str.contains('이익')]\n",
    "        # profit = income[income['tag'].str.contains('영업이익')] # 영업이익(손실) \n",
    "        # profit_tax = income[income['tag'].str.contains('법인세비용차감전')] # t기 법인세비용차감전순이익(손실)\n",
    "        \n",
    "    return fin_state, income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '1ee244d6168bde153cb2d45463d71139f567d1f4'\n",
    "dart = OpenDartReader(api_key)\n",
    "\n",
    "def missed_report_docu_fix(code, year):\n",
    "    lst = dart.list(code, start='2019', end='2024') # 2019-2024 모든 보고서에서 데이터 찾아오기\n",
    "\n",
    "    # 변경1: 원하는 년도의 사업 보고서 고르기 \n",
    "    report_num = lst[(lst['report_nm'].str.contains('사업보고서'))&(lst['report_nm'].str.contains(str(year)))].iloc[0, 5]\n",
    "    url = dart.sub_docs(report_num) #사업보고서 번호를 통해 url 요청\n",
    "    html = url[url['title'].str.contains('연결재무제표')].iloc[0, 1] # url 주소\n",
    "\n",
    "    docu = pd.read_html(html) # 데이터 읽어오기 \n",
    "    fin_state = None\n",
    "    income = None\n",
    "    for index, content in enumerate(docu):\n",
    "        if content.iloc[0,0] =='연결 재무상태표':\n",
    "            fin_state = docu[index+1].rename(columns={'Unnamed: 0': 'tag'}) # 재무상태표\n",
    "            fin_state = fin_state[(fin_state['tag'].str.contains('자산')) | (fin_state['tag'].str.contains('부채'))]\n",
    "            \n",
    "            \n",
    "        elif content.iloc[0,0] =='연결 손익계산서':\n",
    "            income = docu[index+1].rename(columns={'Unnamed: 0': 'tag'}) # 손익계산서\n",
    "            income = income[income['tag'].str.contains('이익')]\n",
    "        \n",
    "    return fin_state, income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022 재무상태표 & 손익계산서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_index, bad_index = [], []\n",
    "\n",
    "for index, code in enumerate(df['stock_code'].unique()):\n",
    "    try:\n",
    "        fin, inc = report_docu(code, 2022)\n",
    "        fin.to_csv(f'./2022/fin_2022/{code}_{str(2022)}.csv', encoding='utf8')\n",
    "        inc.to_csv(f'./2022/inc_2022/{code}_{str(2022)}.csv', encoding='utf8')\n",
    "          \n",
    "        print(f'{index}, Good!') # check if it works well\n",
    "        good_index.append(index)\n",
    "    except:\n",
    "        print(f'{index}, bad...') # check if there is a problem\n",
    "        bad_index.append(index)\n",
    "        \n",
    "print(len(good_index), len(bad_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락 데이터 확인 # dataset_2022\n",
    "\n",
    "file_path1 = './2022/fin_2022'\n",
    "\n",
    "codes = []\n",
    "for f in glob.glob(os.path.join(file_path1, '*.csv')):\n",
    "    code = f.split('_')[1][-6:]\n",
    "    codes.append(code)\n",
    "    \n",
    "missed_code = [code for code in list(df['stock_code'].unique()) if code not in codes]\n",
    "\n",
    "print(len(codes), len(missed_code)) # 185개 기업 데이터 누락\n",
    "\n",
    "df1 = pd.DataFrame(missed_code, columns=['stock_code'])\n",
    "df2 = pd.merge(df1, df[['stock_code', 'corp_name']], on='stock_code', how='left')\n",
    "df2 = df2.drop_duplicates(['stock_code'])\n",
    "df2.head(3)\n",
    "\n",
    "good_index, bad_index = [], []\n",
    "\n",
    "for index, code in enumerate(df2['stock_code'].unique()): # 185개 기업\n",
    "    try:\n",
    "        fin, inc = missed_report_docu_fix(code, 2022)\n",
    "        fin.to_csv(f'./2022/fin_2022/{code}_{str(2022)}.csv', encoding='utf8')\n",
    "        inc.to_csv(f'./2022/inc_2022/{code}_{str(2022)}.csv', encoding='utf8')\n",
    "        good_index.append(index)\n",
    "    except:\n",
    "        bad_index.append(index)\n",
    "        \n",
    "print(len(good_index), len(bad_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 회사 수:  690\n",
      "누락 회사 수:  157\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "entire_codes = []\n",
    "for f in glob.glob(os.path.join('./2022/fin_2022', '*.csv')):\n",
    "    code = f.split('\\\\')[1][:6]\n",
    "    entire_codes.append(code)\n",
    "    \n",
    "code_missing = [code for code in list(df['stock_code'].unique()) if code not in entire_codes]\n",
    "\n",
    "print('저장된 회사 수: ', len(entire_codes)) # 847개 중 690개 # 157개 누락\n",
    "print('누락 회사 수: ', len(code_missing))\n",
    "\n",
    "code_missing.sort()\n",
    "miss_df_2022 = pd.merge(pd.DataFrame(code_missing, columns=['stock_code']), df[['stock_code', 'corp_name']].drop_duplicates(), \n",
    "                        on='stock_code', how='left')\n",
    "miss_df_2022.to_csv('./df_2022_miss.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022 재무상표 & 손익계산서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_index, bad_index = [], []\n",
    "\n",
    "for index, code in enumerate(df['stock_code'].unique()): \n",
    "    try:\n",
    "        fin, inc = report_docu(code, 2020)\n",
    "        fin.to_csv(f'./2020/fin_2020/{code}_{str(2020)}.csv', encoding='utf8')\n",
    "        inc.to_csv(f'./2020/inc_2020/{code}_{str(2020)}.csv', encoding='utf8')\n",
    "          \n",
    "        print(f'{index}, Good!') # check if it works well\n",
    "        good_index.append(index)\n",
    "    except:\n",
    "        print(f'{index}, bad...') # check if there is a problem\n",
    "        bad_index.append(index)\n",
    "        \n",
    "print(len(good_index), len(bad_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락 데이터 확인 # dataset_2020\n",
    "file_path2 = './2020/fin_2020'\n",
    "\n",
    "codes = []\n",
    "for f in glob.glob(os.path.join(file_path2, '*.csv')):\n",
    "    code = f.split('_')[1][-6:]\n",
    "    codes.append(code)\n",
    "    \n",
    "missed_code = [code for code in list(df['stock_code'].unique()) if code not in codes]\n",
    "\n",
    "print(len(codes), len(missed_code)) # 185개 기업 데이터 누락\n",
    "\n",
    "df1 = pd.DataFrame(missed_code, columns=['stock_code'])\n",
    "df2 = pd.merge(df1, df[['stock_code', 'corp_name']], on='stock_code', how='left')\n",
    "df2 = df2.drop_duplicates(['stock_code'])\n",
    "df2.head(3)\n",
    "\n",
    "good_index, bad_index = [], []\n",
    "\n",
    "for index, code in enumerate(df2['stock_code'].unique()): # 185개 기업\n",
    "    try:\n",
    "        fin, inc = missed_report_docu_fix(code, 2020)\n",
    "        fin.to_csv(f'./2020/fin_2020/{code}_{str(2020)}.csv', encoding='utf8')\n",
    "        inc.to_csv(f'./2020/inc_2020/{code}_{str(2020)}.csv', encoding='utf8')\n",
    "        print(f'{index}, Good!') # check if it works well\n",
    "        good_index.append(index)\n",
    "    except:\n",
    "        print(f'{index}, bad...') # check if there is a problem\n",
    "        bad_index.append(index)\n",
    "        \n",
    "print(len(good_index), len(bad_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 회사 수:  670\n",
      "누락 회사 수:  177\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "entire_codes = []\n",
    "for f in glob.glob(os.path.join('./2020/fin_2020', '*.csv')):\n",
    "    code = f.split('\\\\')[1][:6]\n",
    "    entire_codes.append(code)\n",
    "    \n",
    "code_missing = [code for code in list(df['stock_code'].unique()) if code not in entire_codes]\n",
    "\n",
    "print('저장된 회사 수: ', len(entire_codes)) # 847개 중 690개 # 157개 누락\n",
    "print('누락 회사 수: ', len(code_missing)) # 847개 중 177개 누락\n",
    "\n",
    "code_missing.sort()\n",
    "miss_df_2020 = pd.merge(pd.DataFrame(code_missing, columns=['stock_code']), df[['stock_code', 'corp_name']].drop_duplicates(), \n",
    "                        on='stock_code', how='left')\n",
    "miss_df_2020.to_csv('./df_2020_miss.csv', encoding='utf8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
